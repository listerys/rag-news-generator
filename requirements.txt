# Message Queue
kafka-python==2.0.2
confluent-kafka==2.3.0

# HTTP & API
requests==2.31.0
httpx==0.25.0
aiohttp==3.9.0

# Database
psycopg2-binary==2.9.9
redis==5.0.1
sqlalchemy==2.0.23

# LLM - Local inference via Ollama (no additional Python deps needed)
# Ollama runs as a separate Docker service

# Data Processing
pandas==2.1.3
pydantic==2.5.0

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1

# Utilities
python-dotenv==1.0.0
